## Reinforcement Learning and Deep Learning
This repository is dedicated to showcasing the implementation of reinforcement learning and deep learning algorithms/projects  while the process of learning these concepts. Each project has links to its corresponding project repo and README.

#### 1. [Unity and Pybullet ML Agents RL Implementation](#Unity-and-Pybullet-ML-Agents-RL-Implementation)
#### 2. [Follow me-Quadrocopter Simulation ](#Follow-me-Quadrocopter-Simulation)
#### 3. [Rover perception and Control](#Rover-perception-and-Control)
#### 4. [Training Locomotion using Augmented Random Search](#Training-Locomotion-using-Augmented-Random-Search)
#### 5. [Motion Detector Using OpenCV](#Motion-Detector-Using-OpenCV)

## Unity and Pybullet ML Agents RL Implementation
[Unity ML-agents](https://github.com/Unity-Technologies/ml-agents) is an open-source project that enables games and simulations to serve as environments for training intelligent agents. [Pybullet](https://docs.google.com/document/d/10sXEhzFRSnvFcl3XxNGhnD4N2SedqwdAvK3dsihxVUA/edit#heading=h.2ye70wns7io3) is a python module designed for robotics and machine learning applications based on the Bullet Physics SDK.
The list Environments solved (Both Unity and Pybullet) using OpenAi Gym baselines implementations -
- Ant PyBullet Environment using Soft Actor Critic (SAC)
- Unity Banana Environment using Deep Q-network (DQN)
- Cartpole Environment using REINFORCE
- Unity Crawler Environment using Proximal Policy Optimization (PPO)
- Lunar Lander Environment using DDPG
- Unity Tennis Environment using Multi-agent DDPG
- Pybullet Walker2D Environment using Twin-Delayed DDPG

#### Click ðŸ‘‰ for [Project Details](https://github.com/ashutoshtiwari13/Unity-PyBullet-DRL-Hub)

<img src="https://github.com/ashutoshtiwari13/Unity-PyBullet-DRL-Hub/blob/master/Ant-PyBullet-Env-SAC/output/AntEnv-sim2.gif" height="200px" width="180px"/><img src="https://github.com/ashutoshtiwari13/Unity-PyBullet-DRL-Hub/blob/master/Banana-Env-DQN/output/simulation.gif" height="200px" width="180px"/> <img src="https://github.com/ashutoshtiwari13/Unity-PyBullet-DRL-Hub/blob/master/CartPole-Env-REINFORCE/output/sim-2.gif" height="200px" width="180px"/><img src="https://github.com/ashutoshtiwari13/Unity-PyBullet-DRL-Hub/blob/master/Crawler-Env-PPO/output/crawler.gif" height="200px" width="180px"/><img src="https://github.com/ashutoshtiwari13/Unity-PyBullet-DRL-Hub/blob/master/LunarLander-Env-DDPG/output/LL-sim1.gif" height="200px" width="180px"/><img src="https://github.com/ashutoshtiwari13/Unity-PyBullet-DRL-Hub/blob/master/Tennis-Env-MA_DDPG/output/Tennis.gif" height="200px" width="180px"/><img src="https://github.com/ashutoshtiwari13/Unity-PyBullet-DRL-Hub/blob/master/Tennis-Env-MA_DDPG/output/Tennis.gif" height="200px" width="180px"/>


## Follow me-Quadrocopter Simulation
A deep neural network to identify and track a target (person) via a simulated Quadrocopter (Simulated using Udacity QuadSim by Unity). Applications like these are key to many fields of robotics and the very same techniques are used for tasks of advanced cruise control in UAV's , autonomous vehicles and human-robot collaboration in the industry.

#### Click ðŸ‘‰ for [Project Details](https://github.com/ashutoshtiwari13/Quadrocoptorsimulator-Deep-learning)

<p align="center">
<img src="https://github.com/ashutoshtiwari13/Quadrocoptorsimulator-Deep-learning/blob/master/quadsim_simulation.gif" width="750px" height="400px" />
</p>

## Rover perception and Control
This project uses essential elements of Robotics, perception, decision making and Actuation to drive a rover Autonomously.The simulator ran on a resolution of 800x600 with the graphics set to fantastic. From these settings, the rover was able to map most of the map with fidelity from 60% to 70% and find the location of rocks from his navigation path.

#### Click ðŸ‘‰ for [Project Details](https://github.com/ashutoshtiwari13/RoverWorld-perception-Control)

<img src="https://github.com/ashutoshtiwari13/RoverWorld-perception-Control/blob/master/SimulationOutput/simulate2.gif" height="425px" width="380px" hspace="20"/><img src="https://github.com/ashutoshtiwari13/RoverWorld-perception-Control/blob/master/SimulationOutput/simulate1.gif" height="425px" width="400px"/>

## Training Locomotion using Augmented Random Search
The project aims on building a new type of Artificial intelligence algorithm which is simple and surpasses many already available algorithms for Humanoid or Mu-Jo-Co(Multidimensionla-Joint-with-contact) locomotion related tasks. It simulates a powerful AI Algorithm,called Augmented Random Search (ARS) by training a Half-cheetah (Mu-Jo-Co) to walk and run across a field. to walk and run .

#### Click ðŸ‘‰ for [Project Details](https://github.com/ashutoshtiwari13/Simple-Random-Search)

<p align="center">
<img src="https://github.com/ashutoshtiwari13/Simple-Random-Search/blob/master/photos/SS12.jpg" />
</p>

## Motion Detector Using OpenCV
Python/OpenCV script that detect motion on webcam and allow record it to a file and plot a graph for proper Visualization.
The trivial idea is to compute the difference between two frames apply a threshold the separate pixels that have changed from the others and then count all the black pixels. Then the average is calculated with this count and the total number of pixels and depending of the ceil the event is triggered or NOT.

#### Click ðŸ‘‰ for [Project Details](https://github.com/ashutoshtiwari13/Motion-Detector)

<img src="https://github.com/ashutoshtiwari13/Motion-Detector/blob/master/SS2.png" height="425px" width="380px" hspace="20"/><img src="https://github.com/ashutoshtiwari13/Motion-Detector/blob/master/SS4.png" height="425px" width="400px"/>
